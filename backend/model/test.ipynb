{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elgun\n"
     ]
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "print(unicodeToAscii('Elgün'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "data_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    index = all_categories.index(category)\n",
    "    data_df = pd.concat([data_df, pd.DataFrame({'Name':lines,'Country':category,'index':index})])\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khoury</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nahas</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daher</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerges</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nazari</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>Truong</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>Van</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20071</th>\n",
       "      <td>Vinh</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20072</th>\n",
       "      <td>Vuong</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20073</th>\n",
       "      <td>Vuu</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20074 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name     Country  index\n",
       "0      Khoury      Arabic      0\n",
       "1       Nahas      Arabic      0\n",
       "2       Daher      Arabic      0\n",
       "3      Gerges      Arabic      0\n",
       "4      Nazari      Arabic      0\n",
       "...       ...         ...    ...\n",
       "20069  Truong  Vietnamese     17\n",
       "20070     Van  Vietnamese     17\n",
       "20071    Vinh  Vietnamese     17\n",
       "20072   Vuong  Vietnamese     17\n",
       "20073     Vuu  Vietnamese     17\n",
       "\n",
       "[20074 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Russian       9408\n",
       "English       3668\n",
       "Arabic        2000\n",
       "Japanese       991\n",
       "German         724\n",
       "Italian        709\n",
       "Czech          519\n",
       "Spanish        298\n",
       "Dutch          297\n",
       "French         277\n",
       "Chinese        268\n",
       "Irish          232\n",
       "Greek          203\n",
       "Polish         139\n",
       "Scottish       100\n",
       "Korean          94\n",
       "Portuguese      74\n",
       "Vietnamese      73\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = ros.fit_resample(np.array(data_df['Name']).reshape(-1,1),np.array(data_df['index']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_5704\\2438259374.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data_df_balance['Country'] = data_df_balance.apply(lambda row: all_categories[row[1]], axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>index</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khoury</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nahas</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daher</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerges</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nazari</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169339</th>\n",
       "      <td>Dao</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169340</th>\n",
       "      <td>Giang</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169341</th>\n",
       "      <td>Tieu</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169342</th>\n",
       "      <td>Dinh</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169343</th>\n",
       "      <td>Quang</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169344 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  index     Country\n",
       "0       Khoury      0      Arabic\n",
       "1        Nahas      0      Arabic\n",
       "2        Daher      0      Arabic\n",
       "3       Gerges      0      Arabic\n",
       "4       Nazari      0      Arabic\n",
       "...        ...    ...         ...\n",
       "169339     Dao     17  Vietnamese\n",
       "169340   Giang     17  Vietnamese\n",
       "169341    Tieu     17  Vietnamese\n",
       "169342    Dinh     17  Vietnamese\n",
       "169343   Quang     17  Vietnamese\n",
       "\n",
       "[169344 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_balance = pd.DataFrame({'name':x.reshape(1,-1)[0].tolist(),'index':y.reshape(1,-1)[0].tolist()})\n",
    "data_df_balance['Country'] = data_df_balance.apply(lambda row: all_categories[row[1]], axis = 1)\n",
    "data_df_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_5704\\469471141.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data_df_balance['Country'] = data_df_balance.apply(lambda row: all_categories[row[1]], axis = 1)\n"
     ]
    }
   ],
   "source": [
    "data_df_balance['Country'] = data_df_balance.apply(lambda row: all_categories[row[1]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>index</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khoury</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nahas</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daher</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gerges</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nazari</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169339</th>\n",
       "      <td>Dao</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169340</th>\n",
       "      <td>Giang</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169341</th>\n",
       "      <td>Tieu</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169342</th>\n",
       "      <td>Dinh</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169343</th>\n",
       "      <td>Quang</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169344 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  index     Country\n",
       "0       Khoury      0      Arabic\n",
       "1        Nahas      0      Arabic\n",
       "2        Daher      0      Arabic\n",
       "3       Gerges      0      Arabic\n",
       "4       Nazari      0      Arabic\n",
       "...        ...    ...         ...\n",
       "169339     Dao     17  Vietnamese\n",
       "169340   Giang     17  Vietnamese\n",
       "169341    Tieu     17  Vietnamese\n",
       "169342    Dinh     17  Vietnamese\n",
       "169343   Quang     17  Vietnamese\n",
       "\n",
       "[169344 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "Arabic        9408\n",
       "Chinese       9408\n",
       "Spanish       9408\n",
       "Scottish      9408\n",
       "Russian       9408\n",
       "Portuguese    9408\n",
       "Polish        9408\n",
       "Korean        9408\n",
       "Japanese      9408\n",
       "Italian       9408\n",
       "Irish         9408\n",
       "Greek         9408\n",
       "German        9408\n",
       "French        9408\n",
       "English       9408\n",
       "Dutch         9408\n",
       "Czech         9408\n",
       "Vietnamese    9408\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_balance['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic length : 2000\n",
      "Chinese length : 268\n",
      "Czech length : 519\n",
      "Dutch length : 297\n",
      "English length : 3668\n",
      "French length : 277\n",
      "German length : 724\n",
      "Greek length : 203\n",
      "Irish length : 232\n",
      "Italian length : 709\n",
      "Japanese length : 991\n",
      "Korean length : 94\n",
      "Polish length : 139\n",
      "Portuguese length : 74\n",
      "Russian length : 9408\n",
      "Scottish length : 100\n",
      "Spanish length : 298\n",
      "Vietnamese length : 73\n"
     ]
    }
   ],
   "source": [
    "for category in category_lines:\n",
    "    print(f'{category} length : {len(category_lines[category])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, test_data = train_test_split(data_df_balance, test_size=0.10)\n",
    "train_data, valid_data = train_test_split(data,test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "    \n",
    "    def letterToIndex(self,letter):\n",
    "        return all_letters.find(letter)\n",
    "\n",
    "    def lineToTensor(self,line):\n",
    "        tensor = torch.zeros(len(line), 1, n_letters)\n",
    "        for li, letter in enumerate(line):\n",
    "          tensor[li][0][self.letterToIndex(letter)] = 1\n",
    "        return tensor   \n",
    "         \n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        features = self.lineToTensor(row.iloc[0])\n",
    "        label = torch.tensor(row.iloc[-2],dtype=torch.long)\n",
    "        return features, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CreateDataset(dataframe=train_data)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>index</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50196</th>\n",
       "      <td>Reynders</td>\n",
       "      <td>3</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Harb</td>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18478</th>\n",
       "      <td>Vazhenin</td>\n",
       "      <td>14</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139700</th>\n",
       "      <td>Mendes</td>\n",
       "      <td>13</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160088</th>\n",
       "      <td>Chung</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33388</th>\n",
       "      <td>Shi</td>\n",
       "      <td>1</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100707</th>\n",
       "      <td>Di antonio</td>\n",
       "      <td>9</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140788</th>\n",
       "      <td>Rosario</td>\n",
       "      <td>13</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166195</th>\n",
       "      <td>Banh</td>\n",
       "      <td>17</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108108</th>\n",
       "      <td>Miwa</td>\n",
       "      <td>10</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  index     Country\n",
       "50196     Reynders      3       Dutch\n",
       "1589          Harb      0      Arabic\n",
       "18478     Vazhenin     14     Russian\n",
       "139700      Mendes     13  Portuguese\n",
       "160088       Chung     17  Vietnamese\n",
       "...            ...    ...         ...\n",
       "33388          Shi      1     Chinese\n",
       "100707  Di antonio      9     Italian\n",
       "140788     Rosario     13  Portuguese\n",
       "166195        Banh     17  Vietnamese\n",
       "108108        Miwa     10    Japanese\n",
       "\n",
       "[15241 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = CreateDataset(dataframe=valid_data)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CreateDataset(dataframe=test_data)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = iter(train_loader)\n",
    "feature, label = next(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'Chinese',\n",
       " 'Czech',\n",
       " 'Dutch',\n",
       " 'English',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Greek',\n",
       " 'Irish',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'Korean',\n",
       " 'Polish',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Scottish',\n",
       " 'Spanish',\n",
       " 'Vietnamese']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(myRnn, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self,input, hidden):\n",
    "        combined = torch.cat((input,hidden),1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size).to(device)\n",
    "\n",
    "n_hidden = 128\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"LSTM class\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        '''\n",
    "\n",
    "        :param input_size: number of input coming in\n",
    "        :param hidden_size: number of he hidden units\n",
    "        :param output_size: size of the output\n",
    "        '''\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        #LSTM\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size).to(device)\n",
    "        self.hidden2Cat = nn.Linear(hidden_size, output_size).to(device)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(input, self.hidden)\n",
    "        output = self.hidden2Cat(lstm_out[-1]) #many to one\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size).to(device),\n",
    "                torch.zeros(1, 1, self.hidden_size).to(device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "epochs = 11\n",
    "learning_rate = 0.001 # If you set this too high, it might explode. If too low, it might not learn\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories) #LSTM model\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Accuracy:  81.64003266067887 % , Loss 0.23224204778671265\n",
      "Epoch: 1, Accuracy:  92.7446634783623 % , Loss 9.298280929215252e-06\n",
      "Epoch: 2, Accuracy:  93.79957424472181 % , Loss 5.483612312673358e-06\n",
      "Epoch: 3, Accuracy:  94.19762626851744 % , Loss 0.008392306044697762\n",
      "Epoch: 4, Accuracy:  94.43456199696723 % , Loss 0.0020698329899460077\n",
      "Epoch: 5, Accuracy:  94.54100081651697 % , Loss 0.011267011985182762\n",
      "Epoch: 6, Accuracy:  94.63504607488628 % , Loss 0.007473013363778591\n",
      "Epoch: 7, Accuracy:  94.68170418756561 % , Loss 0.4784899353981018\n",
      "Epoch: 8, Accuracy:  94.74294296045726 % , Loss 0.012747940607368946\n",
      "Epoch: 9, Accuracy:  94.82896885570979 % , Loss 0.0019702562130987644\n",
      "Epoch: 10, Accuracy:  94.82313659162487 % , Loss 0.006849026307463646\n"
     ]
    }
   ],
   "source": [
    "def train(category_tensor, line_tensor):\n",
    "    rnn.zero_grad()\n",
    "    rnn.hidden = rnn.init_hidden()\n",
    "    output = rnn(line_tensor)[-1]\n",
    "    loss = criterion(output.unsqueeze(0), category_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return output.unsqueeze(0), loss.item()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    current_loss  = 0\n",
    "    acc = []\n",
    "\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "       \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        out, loss = train(labels,features[0])\n",
    "\n",
    "        top_n, top_i = out.topk(1)\n",
    "        output_category = top_i[0]\n",
    "        # print(output_category)\n",
    "        acc.append(torch.sum(output_category == labels).item())\n",
    "\n",
    "    current_loss += loss\n",
    "    \n",
    "    print(f'Epoch: {epoch}, Accuracy:  {np.mean(acc) * 100} % , Loss {current_loss}')\n",
    "    # if (epoch % 10 == 0):\n",
    "    #     print(f'Epoch: {epoch}')\n",
    "    #     print(f'Loss: {current_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(line_tensor):\n",
    "\n",
    "    rnn.hidden = rnn.init_hidden()\n",
    "    output = rnn(line_tensor)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def letterToIndex(letter):\n",
    "        return all_letters.find(letter)\n",
    "\n",
    "    def lineToTensor(line):\n",
    "        tensor = torch.zeros(len(line), 1, n_letters)\n",
    "        for li, letter in enumerate(line):\n",
    "          tensor[li][0][letterToIndex(letter)] = 1\n",
    "        return tensor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "device_cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m exp_normalize(t\u001b[39m.\u001b[39mto(device_cpu)\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exp_normalize' is not defined"
     ]
    }
   ],
   "source": [
    "exp_normalize(t.to(device_cpu).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m probs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(t\u001b[39m.\u001b[39mto(device_cpu)\u001b[39m.\u001b[39mnumpy()) \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39mexp(t\u001b[39m.\u001b[39mto(device_cpu)\u001b[39m.\u001b[39mnumpy()))\u001b[39m.\u001b[39msum()\n\u001b[0;32m      2\u001b[0m probs\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "probs = np.exp(t.to(device_cpu).numpy()) / (np.exp(t.to(device_cpu).numpy())).sum()\n",
    "probs*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "t = None\n",
    "def predict(input_line, n_predictions=5):\n",
    "    global t\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line).to(device))\n",
    "        t = output\n",
    "       \n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(5, 1, True)\n",
    "        probs = np.exp(topv.to(device_cpu).numpy()) / (np.exp(topv.to(device_cpu).numpy())).sum()\n",
    "        probs*100\n",
    "        predictions = []\n",
    "        for i in range(n_predictions):\n",
    "            value = probs[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Smith\n",
      "(0.92) Scottish\n",
      "(0.07) Czech\n",
      "(0.01) English\n",
      "(0.00) German\n",
      "(0.00) Chinese\n"
     ]
    }
   ],
   "source": [
    "predict('Smith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Rose\n",
      "(0.98) French\n",
      "(0.01) German\n",
      "(0.01) English\n",
      "(0.00) Scottish\n",
      "(0.00) Dutch\n"
     ]
    }
   ],
   "source": [
    "predict('Rose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Shannon\n",
      "(0.99) Irish\n",
      "(0.00) English\n",
      "(0.00) Russian\n",
      "(0.00) Spanish\n",
      "(0.00) Korean\n"
     ]
    }
   ],
   "source": [
    "predict(\"Shannon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.58040810970408"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_acc = []\n",
    "for i, (features, labels) in enumerate(valid_loader):\n",
    "       \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_true.append(labels.item())\n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        output = rnn(features[0])[-1]\n",
    "\n",
    "        top_n, top_i = output.topk(1)\n",
    "        output_category = top_i[0]\n",
    "        pred.append(output_category.item())\n",
    "        \n",
    "        valid_acc.append(torch.sum(output_category == labels).item())\n",
    "\n",
    "np.mean(valid_acc) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      1.00      1.00       835\n",
      "     Chinese       0.96      0.90      0.93       823\n",
      "       Czech       0.97      0.97      0.97       811\n",
      "       Dutch       0.94      0.96      0.95       831\n",
      "     English       0.92      0.84      0.88       834\n",
      "      French       0.92      0.95      0.93       846\n",
      "      German       0.93      0.90      0.91       796\n",
      "       Greek       0.99      1.00      1.00       868\n",
      "       Irish       0.98      0.95      0.96       806\n",
      "     Italian       0.97      0.95      0.96       849\n",
      "    Japanese       0.98      0.99      0.98       875\n",
      "      Korean       0.93      0.91      0.92       879\n",
      "      Polish       0.97      0.99      0.98       847\n",
      "  Portuguese       0.87      1.00      0.93       899\n",
      "     Russian       0.98      0.91      0.94       863\n",
      "    Scottish       0.92      0.99      0.96       857\n",
      "     Spanish       0.95      0.81      0.88       863\n",
      "  Vietnamese       0.90      0.98      0.94       859\n",
      "\n",
      "    accuracy                           0.95     15241\n",
      "   macro avg       0.95      0.95      0.95     15241\n",
      "weighted avg       0.95      0.95      0.95     15241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,pred, target_names=all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.89223501623856"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = []\n",
    "y_true = []\n",
    "pred = []\n",
    "for i, (features, labels) in enumerate(test_loader):\n",
    "       \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_true.append(labels.item())\n",
    "        \n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        output = rnn(features[0])[-1]\n",
    "\n",
    "        top_n, top_i = output.topk(1)\n",
    "        output_category = top_i[0]\n",
    "        pred.append(output_category.item())\n",
    "        \n",
    "        test_acc.append(torch.sum(output_category == labels).item())\n",
    "\n",
    "np.mean(test_acc) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      1.00      1.00       968\n",
      "     Chinese       0.97      0.91      0.94       984\n",
      "       Czech       0.97      0.97      0.97       901\n",
      "       Dutch       0.95      0.97      0.96       910\n",
      "     English       0.93      0.84      0.88       933\n",
      "      French       0.91      0.96      0.93      1005\n",
      "      German       0.95      0.93      0.94       905\n",
      "       Greek       0.99      1.00      1.00       975\n",
      "       Irish       0.98      0.94      0.96       939\n",
      "     Italian       0.96      0.95      0.96       971\n",
      "    Japanese       0.99      0.98      0.98       936\n",
      "      Korean       0.89      0.92      0.91       893\n",
      "      Polish       0.95      0.99      0.97       907\n",
      "  Portuguese       0.89      1.00      0.94       928\n",
      "     Russian       0.97      0.92      0.94       938\n",
      "    Scottish       0.93      0.99      0.96       971\n",
      "     Spanish       0.96      0.84      0.89       947\n",
      "  Vietnamese       0.92      0.98      0.95       924\n",
      "\n",
      "    accuracy                           0.95     16935\n",
      "   macro avg       0.95      0.95      0.95     16935\n",
      "weighted avg       0.95      0.95      0.95     16935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,pred, target_names=all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.21535635133559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc = []\n",
    "y_true = []\n",
    "pred = []\n",
    "for i, (features, labels) in enumerate(train_loader):\n",
    "       \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_true.append(labels.item())\n",
    "        \n",
    "        rnn.hidden = rnn.init_hidden()\n",
    "        output = rnn(features[0])[-1]\n",
    "\n",
    "        top_n, top_i = output.topk(1)\n",
    "        output_category = top_i[0]\n",
    "        pred.append(output_category.item())\n",
    "        \n",
    "        test_acc.append(torch.sum(output_category == labels).item())\n",
    "\n",
    "np.mean(test_acc) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      1.00      1.00      7584\n",
      "     Chinese       0.94      0.91      0.93      7693\n",
      "       Czech       0.98      0.96      0.97      7612\n",
      "       Dutch       0.95      0.95      0.95      7562\n",
      "     English       0.93      0.91      0.92      7591\n",
      "      French       0.94      0.94      0.94      7555\n",
      "      German       0.95      0.93      0.94      7696\n",
      "       Greek       1.00      0.99      1.00      7658\n",
      "       Irish       0.96      0.96      0.96      7616\n",
      "     Italian       0.95      0.95      0.95      7667\n",
      "    Japanese       1.00      0.99      0.99      7570\n",
      "      Korean       0.93      0.90      0.91      7696\n",
      "      Polish       0.97      0.99      0.98      7610\n",
      "  Portuguese       0.87      0.99      0.93      7673\n",
      "     Russian       0.99      0.97      0.98      7614\n",
      "    Scottish       0.94      0.96      0.95      7594\n",
      "     Spanish       0.93      0.83      0.88      7582\n",
      "  Vietnamese       0.91      0.99      0.95      7595\n",
      "\n",
      "    accuracy                           0.95    137168\n",
      "   macro avg       0.95      0.95      0.95    137168\n",
      "weighted avg       0.95      0.95      0.95    137168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,pred, target_names=all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(line_tensor):\n",
    "\n",
    "    model_1.hidden = model_1.init_hidden()\n",
    "    output = model_1(line_tensor)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "t = None\n",
    "def predict(input_line, n_predictions=5):\n",
    "    global t\n",
    "    print('\\n> %s' % input_line)\n",
    "    with torch.no_grad():\n",
    "        output = evaluate(lineToTensor(input_line).to(device))\n",
    "        t = output\n",
    "       \n",
    "        # Get top N categories\n",
    "        topv, topi = output.topk(5, 1, True)\n",
    "        probs = np.exp(topv.to(device_cpu).numpy()) / (np.exp(topv.to(device_cpu).numpy())).sum()\n",
    "        probs*100\n",
    "        predictions = []\n",
    "        for i in range(n_predictions):\n",
    "            value = probs[0][i].item()\n",
    "            category_index = topi[0][i].item()\n",
    "            print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "            predictions.append([value, all_categories[category_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Markiz\n",
      "(0.42) Korean\n",
      "(0.34) Russian\n",
      "(0.17) Polish\n",
      "(0.06) Spanish\n",
      "(0.01) English\n"
     ]
    }
   ],
   "source": [
    "predict('Markiz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rnn.to(torch.device('cpu')).state_dict(), './rnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (lstm): LSTM(57, 128)\n",
       "  (hidden2Cat): Linear(in_features=128, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 128\n",
    "n_letters = 57\n",
    "n_categories = 18\n",
    "model_1 = RNN(n_letters, n_hidden, n_categories)\n",
    "model_1.load_state_dict(torch.load('./rnn.pth'))\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (lstm): LSTM(57, 128)\n",
       "  (hidden2Cat): Linear(in_features=128, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.31739002066726"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = []\n",
    "y_true = []\n",
    "pred = []\n",
    "for i, (features, labels) in enumerate(test_loader):\n",
    "       \n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_true.append(labels.item())\n",
    "        \n",
    "        model_1.hidden = model_1.init_hidden()\n",
    "        output = model_1(features[0])[-1]\n",
    "        top_n, top_i = output.topk(1)\n",
    "        output_category = top_i[0]\n",
    "        # print(output_category)\n",
    "        # print(labels)\n",
    "        pred.append(output_category.item())\n",
    "        \n",
    "        test_acc.append(torch.sum(output_category == labels).item())\n",
    "\n",
    "np.mean(test_acc) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      1.00      1.00       968\n",
      "     Chinese       0.97      0.91      0.94       984\n",
      "       Czech       0.97      0.97      0.97       901\n",
      "       Dutch       0.95      0.97      0.96       910\n",
      "     English       0.93      0.84      0.88       933\n",
      "      French       0.91      0.96      0.93      1005\n",
      "      German       0.95      0.93      0.94       905\n",
      "       Greek       0.99      1.00      1.00       975\n",
      "       Irish       0.98      0.94      0.96       939\n",
      "     Italian       0.96      0.95      0.96       971\n",
      "    Japanese       0.99      0.98      0.98       936\n",
      "      Korean       0.89      0.92      0.91       893\n",
      "      Polish       0.95      0.99      0.97       907\n",
      "  Portuguese       0.89      1.00      0.94       928\n",
      "     Russian       0.97      0.92      0.94       938\n",
      "    Scottish       0.93      0.99      0.96       971\n",
      "     Spanish       0.96      0.84      0.89       947\n",
      "  Vietnamese       0.92      0.98      0.95       924\n",
      "\n",
      "    accuracy                           0.95     16935\n",
      "   macro avg       0.95      0.95      0.95     16935\n",
      "weighted avg       0.95      0.95      0.95     16935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,pred, target_names=all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estevez\n"
     ]
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "print(unicodeToAscii('Estévez'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from  sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='weighted'))\n",
    "\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index=metrics_sum_index)\n",
    "    \n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-1] = total\n",
    "    \n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report.drop(df_class_report.tail(1).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report['Country'] = all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report = pandas_classification_report(y_true,pred,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report.to_csv('report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report.set_index('Country').to_csv('report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
